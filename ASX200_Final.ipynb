{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e382fb9f-b65d-4184-b865-9220d7ebfc05",
   "metadata": {},
   "source": [
    "## Attain HTML for each company market index page"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a326c5a-f5df-4687-b89e-624b78c6bd80",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from bs4 import BeautifulSoup as soup\n",
    "from urllib.request import Request, urlopen\n",
    "import numpy as np\n",
    "import time\n",
    "\n",
    "ASX200 = pd.read_csv(\"ASX200.csv\")\n",
    "ASX200_companies = list(ASX200.Code)\n",
    "\n",
    "def html_get(ticker):\n",
    "    try:\n",
    "        url = f\"https://www.marketindex.com.au/asx/{ticker}\"\n",
    "\n",
    "        req = Request(url, headers={'User-Agent': 'Mozilla/5.0'})\n",
    "        webpage = urlopen(req).read()\n",
    "\n",
    "        # Created html for scraping\n",
    "        html = soup(webpage, \"html.parser\")\n",
    "\n",
    "        return html\n",
    "    \n",
    "    except:\n",
    "        time.sleep(3)\n",
    "        return html_get(ticker)\n",
    "\n",
    "html_dict = {}\n",
    "for ticker in ASX200_companies:\n",
    "    print(ticker)\n",
    "    # Obtaining tables    \n",
    "    html = html_get(ticker)\n",
    "\n",
    "    html_dict[ticker] = str(html)     \n",
    "    \n",
    "import json\n",
    "with open('html_ticker.json', 'w') as fp:\n",
    "    json.dump(html_dict, fp)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce2171ca-8ae5-47bb-a2eb-f4d2ae630ab0",
   "metadata": {},
   "source": [
    "## Attain Top 20 Shareholders and Insider trading tables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8923fb2e-183f-4e4a-bc10-3f73b7a59162",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    " \n",
    "# Opening JSON file\n",
    "f = open('html_ticker.json')\n",
    " \n",
    "# returns JSON object as\n",
    "# a dictionary\n",
    "data = json.load(f)\n",
    " \n",
    "# Insider dataframe stored here\n",
    "insider_df_list = []\n",
    "# Iterating through the json dictionary\n",
    "for ticker in data:\n",
    "    html = data[ticker]\n",
    "    \n",
    "    director = pd.read_html(str(html), attrs = {'class': 'mi-table mb-4'})\n",
    "    \n",
    "    # Checks to confirm that specific table exists\n",
    "    check_insider = False\n",
    "    check_insider_relationship = False \n",
    "    # Going through tables in html code\n",
    "    for table in director:\n",
    "\n",
    "        if list(table.columns) == ['Name', 'Title', 'Since', 'Bio']:\n",
    "            insider_relationship = table\n",
    "            check_insider_relationship = True\n",
    "\n",
    "        if list(table.columns) == ['Date', 'Director', 'Type', 'Amount', 'Price', 'Value', 'Notes']:\n",
    "            insider = table\n",
    "            check_insider = True\n",
    "\n",
    "    if check_insider_relationship == False:\n",
    "        print(f\"{ticker} does not have insider relationship\")\n",
    "\n",
    "    if check_insider == False:\n",
    "        print(f\"{ticker} does not have insider trades\")\n",
    "\n",
    "\n",
    "    # Split name in insider_relationship for ease of finding names\n",
    "    person_name_dict = {}\n",
    "    for person in insider_relationship.Name:\n",
    "        person_name_dict[person] = set(person.split(\" \"))\n",
    "\n",
    "\n",
    "    title_list, bio_list, since_list = [], [], []\n",
    "    for person in insider.Director:\n",
    "        # Splitting name into a list\n",
    "        person_name_list= person.split(\" \")\n",
    "\n",
    "        # Seeing if name list matches name list in insider_relationship\n",
    "        check = False\n",
    "        for key in person_name_dict:\n",
    "            items = person_name_dict[key]\n",
    "\n",
    "            if set(person_name_list).issubset(items) == True:\n",
    "                check = True\n",
    "\n",
    "                # Appending insider_relationship information\n",
    "                title_list.append(insider_relationship[insider_relationship[\"Name\"] == key][\"Title\"].values[0])\n",
    "                bio_list.append(insider_relationship[insider_relationship[\"Name\"] == key][\"Bio\"].values[0])\n",
    "                since_list.append(insider_relationship[insider_relationship[\"Name\"] == key][\"Since\"].values[0])\n",
    "\n",
    "        if check == False:\n",
    "            title_list.append(np.nan)\n",
    "            bio_list.append(np.nan)\n",
    "            since_list.append(np.nan)\n",
    "\n",
    "\n",
    "\n",
    "    insider[\"Title\"] = title_list\n",
    "    insider[\"Bio\"] = bio_list\n",
    "    insider[\"Since\"] = since_list\n",
    "    insider[\"Ticker\"] = len(insider) * [ticker]\n",
    "\n",
    "    insider_df_list.append(insider)\n",
    "        \n",
    "pd.concat(insider_df_list, axis = 0).to_csv(\"insider.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8e0d8ed-a90a-4502-9c41-07e34c1f7692",
   "metadata": {},
   "source": [
    "## Generate graph for insider trades"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7da1688e-29f0-43ae-a184-4ef8b5f73bfd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def graph_insider(ticker_chosen):\n",
    "    import re\n",
    "    import hvplot.pandas\n",
    "    \n",
    "    insider_df = pd.read_csv(\"insider.csv\")\n",
    "    \n",
    "    # Filter for selected ticker\n",
    "    insider_of_ticker_chosen_df = insider_df[insider_df[\"Ticker\"] == ticker_chosen].set_index(\"Date\")\n",
    "    \n",
    "    # Change number from string type to interger\n",
    "    price_list = insider_of_ticker_chosen_df[\"Value\"]\n",
    "    \n",
    "    int_price_list = []\n",
    "    for price in price_list:\n",
    "        if re.findall(\"\\(\", price):\n",
    "            # Removing , from values\n",
    "            price = re.sub(\",\", \"\", price)\n",
    "            # Removing () and $ from negative numbers\n",
    "            int_price_list.append(float(price[2:-1]))\n",
    "        else:\n",
    "            # Removing , from values\n",
    "            price = re.sub(\",\", \"\", price)\n",
    "            # Removing $ from positive numbers\n",
    "            int_price_list.append(float(price[2:]))\n",
    "            \n",
    "    insider_of_ticker_chosen_df[\"Bought/Sold\"] = int_price_list\n",
    "    \n",
    "    display(insider_of_ticker_chosen_df.hvplot.bar(y = \"Bought/Sold\", hover_cols = [\"Director\", \"Price\", \"Value\", \"Type\"]))\n",
    "    \n",
    "graph_insider(\"AAA\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0fda4c4-31f8-4014-a606-69f7854eac21",
   "metadata": {},
   "source": [
    "## Setting up shareholders csv for network "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a96663f9-3604-4cee-803c-a7627b05e35a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extender_color_list(color_list, length_required):\n",
    "    extended_color_list = []\n",
    "    while True:\n",
    "        for color in color_list:\n",
    "            if len(extended_color_list) == length_required:\n",
    "                return extended_color_list\n",
    "            else:\n",
    "                extended_color_list.append(color)\n",
    "\n",
    "def shareholders_connection_graph(ticker_chosen):\n",
    "    import pandas as pd\n",
    "    import re\n",
    "    \n",
    "    top20 = pd.read_csv(\"shareholders.csv\")\n",
    "    \n",
    "    color_list = [\"#FF0000\", \"#FFFFFF\", \"#00FFFF\", \"#C0C0C0\",\"#0000FF\",\"#808080\",\"#00008B\",\"#000000\"\n",
    "                  ,\"#ADD8E6\",\"#FFA500\",\"#800080\",\"#A52A2A\",\"#FFFF00\",\"#800000\",\"#00FF00\",\"#008000\"\n",
    "                  ,\"#FF00FF\",\"#808000\",\"#FFC0CB\"]\n",
    "    \n",
    "\n",
    "    \n",
    "    # Ticker and their nodes created with their weights (Capital)\n",
    "    list_of_shareholders = list(top20[top20[\"Ticker\"] == ticker_chosen][\"Name\"])\n",
    "    list_of_weights = list(top20[top20[\"Ticker\"] == ticker_chosen][\"Capital\"])\n",
    "    list_of_node_num = list(range(len(list_of_shareholders)))\n",
    "\n",
    "    extended_color_list = extender_color_list(color_list, len(list_of_node_num) + 1)\n",
    "    \n",
    "    from pyvis.network import Network\n",
    "\n",
    "    net = Network(notebook = True, bgcolor=\"#222222\", font_color=\"white\")\n",
    "    \n",
    "    # Adding an additional node for ticker chosen\n",
    "    net.add_nodes(list_of_node_num + [list_of_node_num[-1] + 1], label=list_of_shareholders + [ticker_chosen], color = extended_color_list)\n",
    "    \n",
    "    # Adding edges with weights to display top shareholders\n",
    "    ticker_chosen_node_num = list_of_node_num[-1] + 1\n",
    "    for shareholders, weight, node in zip(list_of_shareholders, list_of_weights, list_of_node_num):\n",
    "        weight = float(re.sub(\"%\", \"\", weight))\n",
    "        net.add_edge(node, ticker_chosen_node_num, value = weight)\n",
    "\n",
    "    net.repulsion(node_distance=300, spring_length=200)\n",
    "    net.show_buttons(filter_=True)\n",
    "    display(net.show('list_of_nodes.html'))\n",
    "    \n",
    "shareholders_connection_graph(\"SUN\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73aad171-6906-4eec-a143-1781247fd6a5",
   "metadata": {},
   "source": [
    "## Full Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0354953-8e86-4b39-9768-842ca6703b82",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extender_color_list(color_list, length_required):\n",
    "    extended_color_list = []\n",
    "    while True:\n",
    "        for color in color_list:\n",
    "            if len(extended_color_list) == length_required:\n",
    "                return extended_color_list\n",
    "            else:\n",
    "                extended_color_list.append(color)\n",
    "                \n",
    "def string_cleaner(string):\n",
    "    return \" \".join([word for word in re.sub(\"<.+>|\\(.+\\)\", \"\", string).strip().split(\" \") if word != \"\"])\n",
    "\n",
    "def clean_up_df(df):\n",
    "    # Drop empty cells\n",
    "    df_drop = df.dropna()\n",
    "    \n",
    "    # Drop rows which have either:\n",
    "        # No shareholder information \n",
    "        # No Top 20 shareholder information \n",
    "    # These are present in the Name column\n",
    "    # But also present with 0 shares\n",
    "    \n",
    "    df_drop_0 = df_drop[df_drop[\"Shares\"] != 0]\n",
    "    return df_drop_0\n",
    "\n",
    "import pandas as pd\n",
    "import re\n",
    "\n",
    "shareholders_df_raw = pd.read_csv(\"shareholders.csv\")\n",
    "shareholders_df = clean_up_df(shareholders_df_raw)\n",
    "\n",
    "ticker_asx200 = list(set(shareholders_df[\"Ticker\"]))\n",
    "\n",
    "shareholders_clean = []\n",
    "for shareholder in list(shareholders_df[\"Name\"]):\n",
    "    shareholder_clean = string_cleaner(str(shareholder))\n",
    "    shareholders_clean.append(shareholder_clean)\n",
    "    \n",
    "shareholders_df[\"Name_clean\"] = shareholders_clean\n",
    "\n",
    "unique_shareholders_asx200 = list(set(shareholders_df[\"Name_clean\"]))\n",
    "\n",
    "tickers_and_shareholders = ticker_asx200 + unique_shareholders_asx200\n",
    "\n",
    "nodes_tickers_and_shareholders = list(range(len(tickers_and_shareholders)))\n",
    "\n",
    "color_list = [\"#FF0000\", \"#FFFFFF\", \"#00FFFF\"\n",
    "              , \"#C0C0C0\",\"#0000FF\",\"#808080\"\n",
    "              ,\"#00008B\",\"#ADD8E6\",\"#FFA500\"\n",
    "              ,\"#800080\",\"#A52A2A\",\"#FFFF00\"\n",
    "              ,\"#800000\",\"#00FF00\",\"#008000\"\n",
    "              ,\"#FF00FF\",\"#808000\",\"#FFC0CB\"]\n",
    "\n",
    "extended_color_list = extender_color_list(color_list, len(tickers_and_shareholders))\n",
    "\n",
    "\n",
    "# Creating the network\n",
    "from pyvis.network import Network\n",
    "\n",
    "net = Network(notebook = True, bgcolor=\"#222222\", font_color=\"white\")\n",
    "#net = Network(notebook = True)\n",
    "\n",
    "# Add specifications here\n",
    "# Adding an additional node for ticker chosen\n",
    "for node, color, label in zip(nodes_tickers_and_shareholders, extended_color_list, tickers_and_shareholders):\n",
    "    # If label is a ticker in the ASX200\n",
    "    if label in ticker_asx200:\n",
    "        # Accessing names related to a ticker which is present in the form of 3 capital letters\n",
    "        name_list = list(shareholders_df[shareholders_df[\"Ticker\"] == label][\"Name_clean\"])\n",
    "        # Accessing capital percentage related to a ticker \n",
    "        capital_list = list(shareholders_df[shareholders_df[\"Ticker\"] == label][\"Capital\"])\n",
    "        \n",
    "        title_node = ' Top 20 Shareholders:<br>'\n",
    "        num = 0\n",
    "        for shareholder, capital in zip(name_list, capital_list):\n",
    "            num += 1\n",
    "            title_node += f'<br>{num}) {shareholder}: {capital}'\n",
    "            \n",
    "        img = f\"https://files.marketindex.com.au/xasx/96x96-png/{label.lower()}.png\"\n",
    "        \n",
    "        # Creating the node\n",
    "        net.add_node(n_id = node, label = label, title = title_node, image = img, shape = 'image')\n",
    "        \n",
    "    else:\n",
    "        # Accessing names related to a non-asx200 company\n",
    "        ticker_list = list(shareholders_df[shareholders_df[\"Name_clean\"] == label][\"Ticker\"])\n",
    "        # Accessing capital percentage related to a company \n",
    "        capital_list = list(shareholders_df[shareholders_df[\"Name_clean\"] == label][\"Capital\"])\n",
    "        \n",
    "        title_node = ' Investments:<br>'\n",
    "        num = 0\n",
    "        for shareholder, capital in zip(ticker_list, capital_list):\n",
    "            num += 1\n",
    "            title_node += f'<br>{num}) {shareholder}: {capital}'\n",
    "            \n",
    "        # Creating the node\n",
    "        net.add_node(n_id = node, color = color, label = label, title = title_node)\n",
    "    \n",
    "\n",
    "# Creating a dictionary to know which company is which node\n",
    "company_nodes_dict = {}\n",
    "for company, node in zip(tickers_and_shareholders, nodes_tickers_and_shareholders):\n",
    "    company_nodes_dict[company] = node \n",
    "\n",
    "# Adding network edges for each company\n",
    "for shareholder in unique_shareholders_asx200:\n",
    "    shareholder_investments = list(shareholders_df[shareholders_df[\"Name_clean\"] == shareholder][\"Ticker\"])\n",
    "    shareholder_investments_shares = list(shareholders_df[shareholders_df[\"Name_clean\"] == shareholder][\"Shares\"])\n",
    "    shareholder_investments_capital = list(shareholders_df[shareholders_df[\"Name_clean\"] == shareholder][\"Capital\"])\n",
    "    \n",
    "    shareholder_node = company_nodes_dict[shareholder]\n",
    "    for company, shares, capital in zip(shareholder_investments, shareholder_investments_shares, shareholder_investments_capital):\n",
    "        company_node = company_nodes_dict[company]\n",
    "        \n",
    "        net.add_edge(shareholder_node, company_node, value = shares)\n",
    "        \n",
    "        \n",
    "net.repulsion(node_distance=1500, spring_length=1000)\n",
    "net.save_graph(\"ASX200_network.html\")\n",
    "display(net.show('ASX200.html'))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
